{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "gsQibKtC786Q",
    "outputId": "c5753020-4416-4ec0-94eb-9a41ac241dab"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zzhining/deeplearning_class.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1prEZ3D77D2"
   },
   "outputs": [],
   "source": [
    "# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옵니다.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 필요한 라이브러리를 불러옵니다.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnBjVrm_77D5"
   },
   "source": [
    "## 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "JkRtPQOz77D5",
    "outputId": "c0c23029-034a-4fdb-b4a8-b7b5c4c9494d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_set = np.loadtxt(\"C:/Users/user/ILIFO/DeepLearning/deeplearning_class-master/dataset/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "Data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he3LM-ht77D8"
   },
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "NMb_09_E77D8",
    "outputId": "436f6cf4-9c4a-4cbc-f201-ce18dfd54088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Data_set[:,0:8]\n",
    "Y = Data_set[:,8]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Aib1RiP77EB"
   },
   "source": [
    "## 3. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "DuQYro9v77EC",
    "outputId": "77b49aa8-0273-435f-c33c-d84e9f562252"
   },
   "outputs": [],
   "source": [
    "# 딥러닝 구조를 결정합니다(모델을 설정하고 실행하는 부분입니다).\n",
    "model = Sequential()\n",
    "\n",
    "# 입력데이터 17개의 값을 받아 은닉층 30개 노드로 보낸다\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrivGq-P77EE"
   },
   "source": [
    "## 4. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6ZIbvlx77EE"
   },
   "outputs": [],
   "source": [
    "# 딥러닝을 실행합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AWKHW1b77EG"
   },
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3lQMe5KC77EG",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "36eabce7-89bf-49ba-eab7-51553b94be2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 0s 916us/step - loss: 3.2892 - accuracy: 0.6003\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 850us/step - loss: 1.4579 - accuracy: 0.6341\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 1.1563 - accuracy: 0.6536\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 758us/step - loss: 0.9993 - accuracy: 0.6419\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.9387 - accuracy: 0.6341\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.8630 - accuracy: 0.6302\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 751us/step - loss: 0.8484 - accuracy: 0.6536\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 709us/step - loss: 0.8241 - accuracy: 0.6354\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 751us/step - loss: 0.8164 - accuracy: 0.6276\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 705us/step - loss: 0.7842 - accuracy: 0.6719\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.7185 - accuracy: 0.6393\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 705us/step - loss: 0.7130 - accuracy: 0.6602\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.6959 - accuracy: 0.6654\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.7049 - accuracy: 0.6510\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 752us/step - loss: 0.6612 - accuracy: 0.6602\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 711us/step - loss: 0.6682 - accuracy: 0.6602\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.6586 - accuracy: 0.6758\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 709us/step - loss: 0.6759 - accuracy: 0.6589\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.6692 - accuracy: 0.6523\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 687us/step - loss: 0.6516 - accuracy: 0.6797\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 812us/step - loss: 0.6367 - accuracy: 0.6719\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.6229 - accuracy: 0.6732\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.6398 - accuracy: 0.6771\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.6309 - accuracy: 0.6562\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.6361 - accuracy: 0.6693\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5981 - accuracy: 0.6966\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 813us/step - loss: 0.6170 - accuracy: 0.6875\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.6200 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.7057\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.6296 - accuracy: 0.6797\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 753us/step - loss: 0.5916 - accuracy: 0.6901\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5978 - accuracy: 0.6953\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 796us/step - loss: 0.6030 - accuracy: 0.6901\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.6058 - accuracy: 0.6888\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 978us/step - loss: 0.5936 - accuracy: 0.6888\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 942us/step - loss: 0.5857 - accuracy: 0.7135\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 811us/step - loss: 0.5922 - accuracy: 0.7031\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 784us/step - loss: 0.5675 - accuracy: 0.7266\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 781us/step - loss: 0.6139 - accuracy: 0.6927\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 720us/step - loss: 0.5883 - accuracy: 0.6940\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 789us/step - loss: 0.5823 - accuracy: 0.7018\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 816us/step - loss: 0.6153 - accuracy: 0.6901\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 815us/step - loss: 0.6000 - accuracy: 0.7031\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 821us/step - loss: 0.5731 - accuracy: 0.7122\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 761us/step - loss: 0.5693 - accuracy: 0.7057\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 769us/step - loss: 0.5760 - accuracy: 0.7174\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5901 - accuracy: 0.7031\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5655 - accuracy: 0.7083\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 717us/step - loss: 0.5829 - accuracy: 0.7227\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.5601 - accuracy: 0.7096\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.5636 - accuracy: 0.7331\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7018\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 776us/step - loss: 0.5454 - accuracy: 0.7370\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5686 - accuracy: 0.7161\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 771us/step - loss: 0.5681 - accuracy: 0.7227\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 782us/step - loss: 0.5768 - accuracy: 0.7174\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5809 - accuracy: 0.7018\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5626 - accuracy: 0.7135\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5372 - accuracy: 0.7474\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 893us/step - loss: 0.5471 - accuracy: 0.7240\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.5546 - accuracy: 0.7344\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5647 - accuracy: 0.7305\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 701us/step - loss: 0.5338 - accuracy: 0.7448\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 787us/step - loss: 0.5407 - accuracy: 0.7461\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 772us/step - loss: 0.5351 - accuracy: 0.7344\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 739us/step - loss: 0.5442 - accuracy: 0.7266\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 867us/step - loss: 0.5351 - accuracy: 0.7344\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5549 - accuracy: 0.7161\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 766us/step - loss: 0.5289 - accuracy: 0.7344\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 710us/step - loss: 0.5334 - accuracy: 0.7461\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 896us/step - loss: 0.5274 - accuracy: 0.7448\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 893us/step - loss: 0.5301 - accuracy: 0.7513\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.5181 - accuracy: 0.7526\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 786us/step - loss: 0.5307 - accuracy: 0.7409\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5258 - accuracy: 0.7565\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 778us/step - loss: 0.5275 - accuracy: 0.7396\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.5406 - accuracy: 0.7214\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5213 - accuracy: 0.7422\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.5424 - accuracy: 0.7383\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 902us/step - loss: 0.5353 - accuracy: 0.7292\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 0s 854us/step - loss: 0.5196 - accuracy: 0.7435\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.5245 - accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 803us/step - loss: 0.5294 - accuracy: 0.7552\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 787us/step - loss: 0.5324 - accuracy: 0.7396\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.5128 - accuracy: 0.7734\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 809us/step - loss: 0.5156 - accuracy: 0.7604\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 916us/step - loss: 0.5173 - accuracy: 0.7526\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.5084 - accuracy: 0.7591\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 880us/step - loss: 0.5207 - accuracy: 0.7487\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 861us/step - loss: 0.5152 - accuracy: 0.7643\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 808us/step - loss: 0.5326 - accuracy: 0.7487\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 781us/step - loss: 0.5389 - accuracy: 0.7370\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5217 - accuracy: 0.7578\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4971 - accuracy: 0.7643\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 704us/step - loss: 0.5144 - accuracy: 0.7552\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5058 - accuracy: 0.7513\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 776us/step - loss: 0.5219 - accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5133 - accuracy: 0.7526\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 770us/step - loss: 0.5212 - accuracy: 0.7461\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 751us/step - loss: 0.5130 - accuracy: 0.7578\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5108 - accuracy: 0.7591\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5089 - accuracy: 0.7539\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.5164 - accuracy: 0.7448\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.5206 - accuracy: 0.7409\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 751us/step - loss: 0.5232 - accuracy: 0.7630\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5038 - accuracy: 0.7604\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5118 - accuracy: 0.7708\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.5001 - accuracy: 0.7721\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.4920 - accuracy: 0.7799\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 766us/step - loss: 0.5104 - accuracy: 0.7708\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 719us/step - loss: 0.4991 - accuracy: 0.7695\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 794us/step - loss: 0.5007 - accuracy: 0.7708\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 707us/step - loss: 0.4919 - accuracy: 0.7552\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 778us/step - loss: 0.4916 - accuracy: 0.7734\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 786us/step - loss: 0.4913 - accuracy: 0.7826\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 700us/step - loss: 0.4942 - accuracy: 0.7630\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.5009 - accuracy: 0.7656\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 791us/step - loss: 0.4934 - accuracy: 0.7682\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 699us/step - loss: 0.4998 - accuracy: 0.7591\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.5186 - accuracy: 0.7591\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.5000 - accuracy: 0.7578\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 837us/step - loss: 0.4996 - accuracy: 0.7643\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.4934 - accuracy: 0.7630\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 803us/step - loss: 0.5000 - accuracy: 0.7656\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 821us/step - loss: 0.5185 - accuracy: 0.7487\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7669\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 792us/step - loss: 0.4882 - accuracy: 0.7721\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 781us/step - loss: 0.4954 - accuracy: 0.7708\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 793us/step - loss: 0.5230 - accuracy: 0.7487\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 840us/step - loss: 0.4876 - accuracy: 0.7760\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 894us/step - loss: 0.4835 - accuracy: 0.7747\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.4877 - accuracy: 0.7734\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 819us/step - loss: 0.4943 - accuracy: 0.7708\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 688us/step - loss: 0.5045 - accuracy: 0.7617\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4908 - accuracy: 0.7721\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 928us/step - loss: 0.5015 - accuracy: 0.7630\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.4867 - accuracy: 0.7773\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 812us/step - loss: 0.4894 - accuracy: 0.7747\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.4932 - accuracy: 0.7695\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.4998 - accuracy: 0.7747\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 791us/step - loss: 0.4741 - accuracy: 0.7734\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 757us/step - loss: 0.4823 - accuracy: 0.7760\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 738us/step - loss: 0.4920 - accuracy: 0.7760\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 877us/step - loss: 0.4810 - accuracy: 0.7812\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 959us/step - loss: 0.4907 - accuracy: 0.7695\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 694us/step - loss: 0.4845 - accuracy: 0.7734\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 827us/step - loss: 0.4784 - accuracy: 0.7656\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4910 - accuracy: 0.7591\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 708us/step - loss: 0.4929 - accuracy: 0.7565\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 804us/step - loss: 0.4807 - accuracy: 0.7799\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 785us/step - loss: 0.4815 - accuracy: 0.7826\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 682us/step - loss: 0.4711 - accuracy: 0.7747\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 796us/step - loss: 0.5053 - accuracy: 0.7643\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 777us/step - loss: 0.4965 - accuracy: 0.7604\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 712us/step - loss: 0.4883 - accuracy: 0.7578\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 804us/step - loss: 0.4899 - accuracy: 0.7708\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 798us/step - loss: 0.4775 - accuracy: 0.7852\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 724us/step - loss: 0.4870 - accuracy: 0.7708\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 792us/step - loss: 0.4747 - accuracy: 0.7747\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 775us/step - loss: 0.4904 - accuracy: 0.7695\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 872us/step - loss: 0.4775 - accuracy: 0.7786\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 945us/step - loss: 0.4807 - accuracy: 0.7826\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 853us/step - loss: 0.4768 - accuracy: 0.7943\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 691us/step - loss: 0.4988 - accuracy: 0.7708\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 826us/step - loss: 0.4753 - accuracy: 0.7904\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 815us/step - loss: 0.4829 - accuracy: 0.7747\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 794us/step - loss: 0.4626 - accuracy: 0.7812\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 764us/step - loss: 0.4837 - accuracy: 0.7747\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4674 - accuracy: 0.7826\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 896us/step - loss: 0.4831 - accuracy: 0.7721\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 776us/step - loss: 0.4838 - accuracy: 0.7643\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 761us/step - loss: 0.4704 - accuracy: 0.7708\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 743us/step - loss: 0.4701 - accuracy: 0.7747\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.4665 - accuracy: 0.7852\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 937us/step - loss: 0.4653 - accuracy: 0.7878\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 775us/step - loss: 0.4736 - accuracy: 0.7747\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 784us/step - loss: 0.4828 - accuracy: 0.7799\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 790us/step - loss: 0.4805 - accuracy: 0.7799\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 815us/step - loss: 0.4774 - accuracy: 0.7865\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 803us/step - loss: 0.4705 - accuracy: 0.7891\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 773us/step - loss: 0.4856 - accuracy: 0.7865\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 801us/step - loss: 0.4876 - accuracy: 0.7865\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 815us/step - loss: 0.4623 - accuracy: 0.7865\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 828us/step - loss: 0.4596 - accuracy: 0.7956\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 646us/step - loss: 0.4703 - accuracy: 0.7708\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 597us/step - loss: 0.4698 - accuracy: 0.7773\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 586us/step - loss: 0.4766 - accuracy: 0.7695\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 649us/step - loss: 0.4624 - accuracy: 0.7930\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 649us/step - loss: 0.4567 - accuracy: 0.7891\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 650us/step - loss: 0.4685 - accuracy: 0.7760\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 839us/step - loss: 0.4614 - accuracy: 0.7878\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 673us/step - loss: 0.4623 - accuracy: 0.7904\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 725us/step - loss: 0.4746 - accuracy: 0.7904\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 900us/step - loss: 0.4740 - accuracy: 0.7839\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7943\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 697us/step - loss: 0.4546 - accuracy: 0.7747\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 648us/step - loss: 0.4623 - accuracy: 0.8021\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 528us/step - loss: 0.4636 - accuracy: 0.7839\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 841us/step - loss: 0.4634 - accuracy: 0.7865\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# epoch= 100: 샘플이 처음부터 끝까지 100번 재사용될 때까지 실행을 반복\n",
    "# batch_size = 10: 전체 470개 샘플을 10개씩 끊어서 집어넣기\n",
    "h = model.fit(X, Y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "i7OGN3GX9NUB",
    "outputId": "994d22a8-378d-4857-d95f-05bdcd22ebc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWiEMr4h9pbs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ch11.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
